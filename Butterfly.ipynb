{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-28T14:07:04.919057Z","iopub.execute_input":"2022-03-28T14:07:04.919465Z","iopub.status.idle":"2022-03-28T14:07:06.252618Z","shell.execute_reply.started":"2022-03-28T14:07:04.919401Z","shell.execute_reply":"2022-03-28T14:07:06.251611Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Importing Required Packages/Libraries\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport ntpath\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import Dataset\nimport matplotlib.image as mpimg\nimport cv2\nfrom imgaug import augmenters as iaa\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\nfrom torchvision.utils import save_image\nfrom torchvision.io import read_image\nimport os\nimport random\nfrom datetime import datetime\nfrom torch import device\nimport torch.optim as optim\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2022-03-28T14:07:06.257339Z","iopub.execute_input":"2022-03-28T14:07:06.257812Z","iopub.status.idle":"2022-03-28T14:07:07.775633Z","shell.execute_reply.started":"2022-03-28T14:07:06.257766Z","shell.execute_reply":"2022-03-28T14:07:07.774712Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"example_data = pd.read_csv(\"/kaggle/input/deep-learning-for-msc-coursework-2022/example.csv\")\nprint(example_data.head())","metadata":{"execution":{"iopub.status.busy":"2022-03-28T14:07:07.776913Z","iopub.execute_input":"2022-03-28T14:07:07.777132Z","iopub.status.idle":"2022-03-28T14:07:07.793186Z","shell.execute_reply.started":"2022-03-28T14:07:07.777107Z","shell.execute_reply":"2022-03-28T14:07:07.792113Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# make sure you use the GPU (btw check your runtime is a GPU in colab)\nuse_cuda = True\ndevice = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2022-03-28T14:07:07.796830Z","iopub.execute_input":"2022-03-28T14:07:07.797864Z","iopub.status.idle":"2022-03-28T14:07:07.803789Z","shell.execute_reply.started":"2022-03-28T14:07:07.797807Z","shell.execute_reply":"2022-03-28T14:07:07.802772Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#Data Augmentation\ntrain_transform = transforms.Compose([transforms.RandomRotation(15),\n                                      transforms.RandomResizedCrop(32),\n                                      transforms.RandomHorizontalFlip(0.7),\n                                      transforms.RandomVerticalFlip(0.7),\n                                      transforms.ToTensor()])\n\ntest_transform = transforms.Compose([transforms.RandomRotation(15),\n                                     transforms.RandomResizedCrop(32),\n                                     transforms.RandomHorizontalFlip(0.7),\n                                     transforms.RandomVerticalFlip(0.7),\n                                     transforms.ToTensor()])\n\n#Splitting train & validation data\ntemp_data = torchvision.datasets.ImageFolder(\"../input/deep-learning-for-msc-coursework-2022/train/train\", train_transform)\ntrain_data, validation_data = torch.utils.data.random_split(temp_data, [1500, 200])\n\n#Fetching test data\ntest_data = torchvision.datasets.ImageFolder(\"../input/deep-learning-for-msc-coursework-2022/test\", test_transform)\n\n#Loading all data using a dataloader\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size = 32)\nvalidation_loader = torch.utils.data.DataLoader(validation_data, batch_size = 32)\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size = 32)\n\npath = '../input/deep-learning-for-msc-coursework-2022/'","metadata":{"execution":{"iopub.status.busy":"2022-03-28T14:07:07.805871Z","iopub.execute_input":"2022-03-28T14:07:07.806263Z","iopub.status.idle":"2022-03-28T14:07:07.862450Z","shell.execute_reply.started":"2022-03-28T14:07:07.806212Z","shell.execute_reply":"2022-03-28T14:07:07.861644Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def imageshow(img):\n    npimg= img.numpy()\n    plt.imshow(np.transpose(npimg,(1,2,0)))\n    plt.show()\n\ndataiter=iter(train_loader)\n\nimages,labels=dataiter.next()\nimageshow(torchvision.utils.make_grid(images))","metadata":{"execution":{"iopub.status.busy":"2022-03-28T14:07:07.863813Z","iopub.execute_input":"2022-03-28T14:07:07.864625Z","iopub.status.idle":"2022-03-28T14:07:08.174407Z","shell.execute_reply.started":"2022-03-28T14:07:07.864569Z","shell.execute_reply":"2022-03-28T14:07:08.173484Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#CNN \nclass CNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1=nn.Conv2d(3,28,3)\n        self.pool = nn.MaxPool2d(2,2)\n        \n        self.conv2=nn.Conv2d(28,16,3)\n        self.dropout= nn.Dropout2d(0.2)\n        \n        self.fc1=nn.Linear(576,1024)\n        self.fc2= nn.Linear(1024,60)\n        self.fc3 = nn.Linear(60,4)\n    \n    def forward(self,x):\n        x=self.pool(F.relu(self.conv1(x)))\n        x=self.pool(F.relu(self.conv2(x)))\n        \n        x=torch.flatten(x,1)\n        \n        x= F.relu(self.fc1(x))\n        x= F.relu(self.fc2(x))        \n        x= self.fc3(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-03-28T14:07:08.175869Z","iopub.execute_input":"2022-03-28T14:07:08.176735Z","iopub.status.idle":"2022-03-28T14:07:08.188265Z","shell.execute_reply.started":"2022-03-28T14:07:08.176685Z","shell.execute_reply":"2022-03-28T14:07:08.187307Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"mymodel = CNN()\nprint(mymodel)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T14:07:08.190067Z","iopub.execute_input":"2022-03-28T14:07:08.190479Z","iopub.status.idle":"2022-03-28T14:07:08.212574Z","shell.execute_reply.started":"2022-03-28T14:07:08.190433Z","shell.execute_reply":"2022-03-28T14:07:08.211574Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#Loss function and optimiser\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(mymodel.parameters(), lr=0.001, weight_decay=0.01)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T14:07:08.213907Z","iopub.execute_input":"2022-03-28T14:07:08.214418Z","iopub.status.idle":"2022-03-28T14:07:08.219225Z","shell.execute_reply.started":"2022-03-28T14:07:08.214358Z","shell.execute_reply":"2022-03-28T14:07:08.218447Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_images, train_labels = next(iter(train_loader))\ngrid = torchvision.utils.make_grid(train_images)\nplt.imshow(np.transpose(grid.numpy(), (1,2,0)), interpolation='nearest')","metadata":{"execution":{"iopub.status.busy":"2022-03-28T14:07:08.220600Z","iopub.execute_input":"2022-03-28T14:07:08.222814Z","iopub.status.idle":"2022-03-28T14:07:08.501708Z","shell.execute_reply.started":"2022-03-28T14:07:08.222769Z","shell.execute_reply":"2022-03-28T14:07:08.499870Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#Training model\ntraining_loss = []\nvalidation_loss = []\n\n# Number of iterations\nnum_epochs=25\n\nfor epoch in range(num_epochs):\n    train_loss = 0\n    valid_loss = 0\n    \n    mymodel.train()\n    \n    for train_image, train_target in train_loader:\n        train_image = train_image\n        train_target = train_target\n        \n        #clearing the gradients\n        optimizer.zero_grad()\n        \n        output = mymodel(train_image)\n        \n        #calculating the loss and comparing labels\n        loss= criterion(output,train_target) \n        \n        #backward \n        loss.backward(retain_graph=True)\n        loss.backward()\n        \n        # parameter update\n        optimizer.step() \n        \n        # Update training loss \n        train_loss += loss.item() * train_image.size(0)\n        \n#Evaluting the model\n    mymodel.eval()\n\n#Calculating the validation loss\n    for val_img, val_target in validation_loader:\n        val_img = val_img\n        val_target = val_target\n   \n        val_output = mymodel(val_img)\n    \n        val_loss = criterion(val_output, val_target)\n        \n        #update validation loss\n        valid_loss += val_loss.item() * val_img.size(0)\n    \n#Calculate average loss across all epochs\n    train_loss = train_loss/len(train_loader.sampler)\n    valid_loss = valid_loss/len(validation_loader.sampler)\n    training_loss.append(train_loss)\n    validation_loss.append(valid_loss)\n    print('Epoch:{:.0f} \\t Training Loss:{:.4f}\\tValidation Loss:{:.4f}'.format(epoch+1,train_loss,valid_loss))\n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-28T14:07:08.502807Z","iopub.execute_input":"2022-03-28T14:07:08.503652Z","iopub.status.idle":"2022-03-28T14:08:34.645424Z","shell.execute_reply.started":"2022-03-28T14:07:08.503612Z","shell.execute_reply":"2022-03-28T14:08:34.644444Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#Plot training and validation loss\nplt.plot(training_loss, label ='Training loss')\nplt.plot(validation_loss,label='Validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss at each epoch')\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2022-03-28T14:08:34.647087Z","iopub.execute_input":"2022-03-28T14:08:34.647466Z","iopub.status.idle":"2022-03-28T14:08:34.907517Z","shell.execute_reply.started":"2022-03-28T14:08:34.647417Z","shell.execute_reply":"2022-03-28T14:08:34.906524Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#Calculating Accuracy\ntemp = 0\ntotal = 0\nwith torch.no_grad():\n    for val_images,val_labels in validation_loader:\n        val_images = val_images\n        val_labels = val_labels\n        val_outputs = mymodel(val_images)\n        _,predicted = torch.max(val_outputs.data,1)\n        total+= labels.size(0)\n        temp += (predicted == val_labels).sum().item()\n    print(f'Accuracy of the network on the validation images :{100 * temp /total}%')","metadata":{"execution":{"iopub.status.busy":"2022-03-28T14:08:34.910251Z","iopub.execute_input":"2022-03-28T14:08:34.910533Z","iopub.status.idle":"2022-03-28T14:08:35.228358Z","shell.execute_reply.started":"2022-03-28T14:08:34.910502Z","shell.execute_reply":"2022-03-28T14:08:35.227280Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#Saving Model\nsaved_model = torch.save(mymodel.state_dict(), \"CNN.pt\")","metadata":{"execution":{"iopub.status.busy":"2022-03-28T14:08:35.229807Z","iopub.execute_input":"2022-03-28T14:08:35.230077Z","iopub.status.idle":"2022-03-28T14:08:35.240834Z","shell.execute_reply.started":"2022-03-28T14:08:35.230043Z","shell.execute_reply":"2022-03-28T14:08:35.239877Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"sub_dataset = torchvision.datasets.ImageFolder(path + 'test/', transform=transforms.Compose([\n                                   transforms.ToTensor(),                                   \n                                    ]))\n\n\nsub_dataloader = torch.utils.data.DataLoader(sub_dataset)\n\n#Prediction and Submission part\nmymodel.eval()\nwith torch.no_grad():\n    prediction = []\n    for image, label in sub_dataloader:\n        output = mymodel(image)\n        prediction.append(torch.argmax(output,1))\n        \nsubmission_df = pd.read_csv( path + 'example.csv')\nsubmission_df.drop(columns='Type', inplace=True)\nsubmission_df['Type'] = np.array(prediction)\n\n#Mapping the label names for numerical targets\ndef remap(x):\n    if x == 0 :\n        return 'Cancer'\n    if x == 1:\n        return 'Connective'\n    if x == 2:\n        return 'Immune'\n    if x == 3:\n        return 'Normal'\n\nsubmission_df['Type'] = submission_df['Type'].apply(remap)\n\nsubmission_df.to_csv('test.csv',index=False)\nprint(submission_df)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T14:08:35.242893Z","iopub.execute_input":"2022-03-28T14:08:35.243604Z","iopub.status.idle":"2022-03-28T14:08:41.698795Z","shell.execute_reply.started":"2022-03-28T14:08:35.243553Z","shell.execute_reply":"2022-03-28T14:08:41.697886Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}